{"cells":[{"cell_type":"code","execution_count":139,"metadata":{"executionInfo":{"elapsed":110,"status":"ok","timestamp":1751720733671,"user":{"displayName":"Baidaouy Ziad","userId":"17671220302809145700"},"user_tz":-60},"id":"FQ8JUtdTDtdK"},"outputs":[],"source":["import pandas as pd\n","from bs4 import BeautifulSoup\n","import requests\n","\n","def scan_url(url): # Return the full html !\n","  headers = {\n","      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:119.0) Gecko/20100101 Firefox/119.0\",\n","      \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n","      \"Accept-Language\": \"en-US,en;q=0.9\",\n","      \"Connection\": \"keep-alive\",\n","      \"DNT\": \"1\",\n","      \"Upgrade-Insecure-Requests\": \"1\",\n","  }\n","  response = requests.get(url , headers=headers)\n","  soup = BeautifulSoup(response.text, 'html.parser')\n","  return soup\n","\n","def get_href(url) : # Return every HREF from an url !\n","  all_links = []\n","  soup = scan_url(url)\n","  divs = soup.find_all('div' , attrs = {'class' : 'x-card x-card-flex'})\n","  for i in range(len(divs)) :\n","    a = divs[i].find('a' , {'class' : 'ux-action'})\n","    link = a.get('href')\n","    all_links.append(link)\n","  return all_links\n","\n","def get_data(url) :\n","  titles = []\n","  prices = []\n","  rates = []\n","  reviews = []\n","  links_to_get = get_href(url)\n","  df = pd.DataFrame({'Title' : titles , 'Price' : prices , 'Reviews' : reviews, 'Rates' : rates}) # to ignore local variable problem !\n","  for i in links_to_get :\n","    soup = scan_url(i)\n","    if soup is None:\n","        titles.append(None)\n","        prices.append(None)\n","        rates.append(None)\n","        continue\n","\n","    title_div = soup.find('div', attrs = {'class' : 'vim x-item-title'})\n","    title = None\n","    if title_div:\n","      title_span = title_div.find('span' , attrs = {'class' : 'ux-textspans'})\n","      if title_span:\n","        title = title_span.text.strip()\n","\n","    price_div = soup.find('div', attrs = {'class' : 'x-price-primary'})\n","    price = None\n","    if price_div:\n","      price_span = price_div.find('span' , attrs = {'class' : 'ux-textspans'})\n","      if price_span:\n","        price = price_span.text.strip()\n","\n","    rate_div = soup.find('div' , attrs = {'class' : 'vim x-star-rating'})\n","    rate = None\n","    if rate_div:\n","      rate_span = rate_div.find('span' , attrs = {'class' , 'ux-textspans'})\n","      review_span = rate_div.find('span' , attrs = {'class' , 'ux-textspans ux-textspans--PSEUDOLINK'})\n","      if rate_span and review_span :\n","        rate = rate_span.text\n","        review = review_span.text\n","\n","    titles.append(title)\n","    prices.append(price)\n","    rates.append(rate)\n","    reviews.append(review)\n","    df = pd.DataFrame({'Title' : titles , 'Price' : prices , 'Reviews' : reviews, 'Rates' : rates})\n","  return df\n","\n","\n","# In my example i will use this url : url = 'https://www.ebay.com/t/Computers-Tablets-Network-Hardware/58058/bn_1865247'\n","# my usage : ebay_products = get_data(url)\n","\n","\n","def clean_data(df) :\n","  df.dropna(subset=['Title','Price'], inplace = True)\n","  df.Price = df.Price.str.replace('$','')\n","  df.Price = df.Price.str.replace('C','')\n","  df.Reviews = df.Reviews.str.split(' ').str[0]\n","  return df\n","\n","df.to_csv('output.csv', index = False)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN66L+zQuF11bcwQ7+YgAKb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}